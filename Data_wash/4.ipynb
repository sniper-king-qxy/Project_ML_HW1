{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-28T08:56:31.380183Z",
     "start_time": "2025-03-28T08:56:31.370808Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing  import StandardScaler\n",
    "\n",
    "class SOCPredictor:\n",
    "    def __init__(self, model_path, scaler_path):\n",
    "        # 硬件配置检测\n",
    "        self.device  = torch.device(\"cuda\"  if torch.cuda.is_available()  else \"cpu\")\n",
    "\n",
    "        # 模型结构定义（必须与训练时完全一致）\n",
    "        self.model  = self._define_model_structure().to(self.device)\n",
    "        self.model.load_state_dict(torch.load(model_path,  map_location=self.device))\n",
    "        self.model.eval()\n",
    "\n",
    "        # 加载标准化器\n",
    "        self.scaler  = self._load_scaler(scaler_path)\n",
    "\n",
    "    def _define_model_structure(self):\n",
    "        \"\"\"模型结构定义（需与训练代码完全一致）\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(3, 128),  # 输入层 -> 隐藏层1\n",
    "            nn.LeakyReLU(0.01),  # 负区间保留0.01斜率\n",
    "            nn.BatchNorm1d(128),  # 批量归一化加速收敛\n",
    "            nn.Linear(128, 64),  # 隐藏层1 -> 隐藏层2\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(0.1),  # 随机丢弃10%神经元\n",
    "            nn.Linear(64, 32),  # 隐藏层2 -> 隐藏层3\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(32, 1)  # 输出层\n",
    "        )\n",
    "\n",
    "    def _load_scaler(self, path):\n",
    "        \"\"\"加载标准化器对象\"\"\"\n",
    "        scaler = StandardScaler()\n",
    "        scaler.mean_,  scaler.scale_  = np.load(path,  allow_pickle=True)\n",
    "        return scaler\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        \"\"\"\n",
    "        输入数据格式要求：\n",
    "        - DataFrame或可转换为DataFrame的数据结构\n",
    "        - 列顺序：Voltage, Current, Temperature\n",
    "        \"\"\"\n",
    "        # 数据校验\n",
    "        assert input_data.shape[1]  == 3, \"输入数据需要包含3个特征\"\n",
    "\n",
    "        # 数据预处理\n",
    "        processed_data = self.scaler.transform(input_data)\n",
    "        tensor_data = torch.tensor(processed_data,  dtype=torch.float32).to(self.device)\n",
    "\n",
    "        # 执行预测\n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(tensor_data).cpu().numpy().flatten()\n",
    "\n",
    "        return predictions"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T08:56:33.582985Z",
     "start_time": "2025-03-28T08:56:33.577947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 示例输入数据（需替换为实际数据）\n",
    "new_data = pd.DataFrame({\n",
    "    'Voltage': [3.7, 3.5, 3.8],\n",
    "    'Current': [2.1, 1.8, 2.3],\n",
    "    'Temperature': [25.0, 28.5, 23.7]\n",
    "})\n",
    "\n",
    "# 数据顺序验证\n",
    "input_data = new_data[['Voltage', 'Current', 'Temperature']].values"
   ],
   "id": "5c86a46382b3e2a6",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T08:56:35.539680Z",
     "start_time": "2025-03-28T08:56:35.496670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictor = SOCPredictor(\n",
    "    model_path=\"best_model.pth\",\n",
    "    scaler_path=\"scaler_params.npy\"   # 需保存训练时的scaler参数\n",
    ")"
   ],
   "id": "5131c9ebf295be5e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_28112\\3584257498.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(model_path,  map_location=self.device))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Sequential:\n\tMissing key(s) in state_dict: \"0.weight\", \"0.bias\", \"2.weight\", \"2.bias\", \"2.running_mean\", \"2.running_var\", \"3.weight\", \"3.bias\", \"6.weight\", \"6.bias\", \"8.weight\", \"8.bias\". \n\tUnexpected key(s) in state_dict: \"net.0.weight\", \"net.0.bias\", \"net.2.weight\", \"net.2.bias\", \"net.2.running_mean\", \"net.2.running_var\", \"net.2.num_batches_tracked\", \"net.3.weight\", \"net.3.bias\", \"net.6.weight\", \"net.6.bias\", \"net.8.weight\", \"net.8.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m predictor \u001B[38;5;241m=\u001B[39m \u001B[43mSOCPredictor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbest_model.pth\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscaler_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscaler_params.npy\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m   \u001B[49m\u001B[38;5;66;43;03m# 需保存训练时的scaler参数\u001B[39;49;00m\n\u001B[0;32m      4\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[9], line 14\u001B[0m, in \u001B[0;36mSOCPredictor.__init__\u001B[1;34m(self, model_path, scaler_path)\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# 模型结构定义（必须与训练时完全一致）\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel  \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_define_model_structure()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m---> 14\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# 加载标准化器\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:2215\u001B[0m, in \u001B[0;36mModule.load_state_dict\u001B[1;34m(self, state_dict, strict, assign)\u001B[0m\n\u001B[0;32m   2210\u001B[0m         error_msgs\u001B[38;5;241m.\u001B[39minsert(\n\u001B[0;32m   2211\u001B[0m             \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing key(s) in state_dict: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   2212\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m missing_keys)))\n\u001B[0;32m   2214\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(error_msgs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 2215\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mError(s) in loading state_dict for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   2216\u001B[0m                        \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(error_msgs)))\n\u001B[0;32m   2217\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for Sequential:\n\tMissing key(s) in state_dict: \"0.weight\", \"0.bias\", \"2.weight\", \"2.bias\", \"2.running_mean\", \"2.running_var\", \"3.weight\", \"3.bias\", \"6.weight\", \"6.bias\", \"8.weight\", \"8.bias\". \n\tUnexpected key(s) in state_dict: \"net.0.weight\", \"net.0.bias\", \"net.2.weight\", \"net.2.bias\", \"net.2.running_mean\", \"net.2.running_var\", \"net.2.num_batches_tracked\", \"net.3.weight\", \"net.3.bias\", \"net.6.weight\", \"net.6.bias\", \"net.8.weight\", \"net.8.bias\". "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2c01b6eed72d3dff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
